#!/bin/bash
#==========================================================
# CaMa-Flood sample go script (4) global 15min simulation with "external runoff data"
# Please follow the doc/Guideline.Md about detail, You need to download external runoff data not included in the package to execute this script.
# -- Long-term  simulations (1980 spinup -> 1980 ~ 2014)
# -- Daily runoff forcing (netCDF) at 15min resolution from "E2O WRR2 WCMEF" is used
# -- input matrix is same as the sample ruoff data (test-15min_nc)
#
# (C) X. Zhou, D.Yamazaki & E. Dutra  (U-Tokyo/FCUL)  Feb 2021
#
# Licensed under the Apache License, Version 2.0 (the "License");
#   You may not use this file except in compliance with the License.
#   You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software distributed under the License is 
#  distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
# See the License for the specific language governing permissions and limitations under the License.
#==========================================================

#*** PBS setting when needed
#SBATCH --job-name=US_CITIES_DEM
#SBATCH --time=6:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=16
#SBATCH --gpus=2
#SBATCH --gpu_cmode=shared
#SBATCH --mem=256G
#SBATCH -p serc

#================================================
# (0) Basic Setting (for workstation)

##
ml python/3.12.1
ml cuda/12.6.1
export HF_HOME=/home/users/li1995/global_flood/FloodRisk-DL/terratorch
cd /home/users/li1995/global_flood/FloodRisk-DL/terratorch/meta_learning
source /home/users/li1995/global_flood/FloodRisk-DL/.venv/bin/activate

# Base directory containing all DEM data
DEM_BASE_DIR="/home/users/li1995/global_flood/FloodRisk-DL/data/download_US_DEM"

# Loop through each city folder
#for city_folder in $(ls -d "$DEM_BASE_DIR"/dem_data_Harris_TX_geoid* | sort -r); do
for city_folder in $(ls -d "$DEM_BASE_DIR"/dem_data_Harris_TX_geoid*); do
    if [ -d "$city_folder" ]; then
        city_name=$(basename "$city_folder")
        echo "Processing city: $city_name"
        
        # Loop through each .tif file in the city folder
        for dem_file in "$city_folder"/USGS*.tif; do
        #for dem_file in $(ls -d "$city_folder"/USGS*.tif | sort -r); do
            if [ -f "$dem_file" ]; then
                dem_filename=$(basename "$dem_file")
                echo "Processing DEM: $dem_filename"

                # Check if output file already exists
                output_filename="$city_folder/inference_${dem_filename}"
                if [ -f "$output_filename" ]; then
                    echo "Output file already exists, skipping: $output_filename"
                    continue
                fi
                
                # Get location-specific precipitation data
                echo "Getting precipitation data for $dem_filename..."
                rainfall_mm=$(python get_precipitation.py "$dem_file")
                echo "Using rainfall: ${rainfall_mm}mm for 1-hour, 500-year return period"
                
                # Run the inference for this DEM file
                
                python dem_inference.py \
                    --dem_file="$dem_file" \
                    --rainfall_mm="$rainfall_mm" \
                    --batch_size=5000000 \
                    --output_file="$output_filename"
                
                # Check if the command was successful
                if [ $? -eq 0 ]; then
                    echo "Successfully processed: $dem_filename"
                else
                    echo "Error processing: $dem_filename"
                fi
            fi
        done
    fi
done
echo "All DEM files have been processed."
