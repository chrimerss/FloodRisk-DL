#!/usr/bin/env python
# coding: utf-8

"""
Plot script to visualize results generated by dem_inference_window_by_window.py
This script loads Zarr-based prediction results and creates visualizations
similar to the dem_inference.py plotting functionality.
"""

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
import argparse
from pathlib import Path
import xarray as xr
import warnings
from pyproj import Transformer

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from test_metric import FLOOD_COLORS, FloodCategory

def load_zarr_prediction(zarr_file):
    """
    Load prediction results from Zarr file.
    
    Args:
        zarr_file: Path to the Zarr prediction file
        
    Returns:
        Dictionary with prediction data and metadata
    """
    try:
        print(f"Loading prediction results from: {zarr_file}")
        
        # Load Zarr file using xarray
        ds = xr.open_zarr(zarr_file)
        
        # Get the prediction data - look for flood_prediction variable
        if 'flood_prediction' in ds.data_vars:
            var_name = 'flood_prediction'
            da = ds[var_name]
        elif len(ds.data_vars) > 1:
            # Skip spatial_ref and get the actual prediction data
            data_vars = [v for v in ds.data_vars.keys() if v != 'spatial_ref']
            if data_vars:
                var_name = data_vars[0]
                da = ds[var_name]
            else:
                raise ValueError("No prediction data variable found")
        else:
            da = ds
            
        print(f"Loaded prediction variable: {var_name if 'var_name' in locals() else 'default'}")
        print(f"Prediction shape: {da.shape}")
        
        # Load prediction data into memory
        prediction_array = da.values
        
        # Extract metadata
        crs_str = da.attrs.get('crs', None)
        
        # If CRS not found in data variable, check spatial_ref
        if crs_str is None and 'spatial_ref' in ds:
            spatial_ref = ds['spatial_ref']
            # Try to extract EPSG code from spatial_ref attributes
            if 'crs_wkt' in spatial_ref.attrs:
                crs_wkt = spatial_ref.attrs['crs_wkt']
                if 'EPSG","26915"' in crs_wkt:
                    crs_str = 'EPSG:26915'
                elif 'AUTHORITY["EPSG",' in crs_wkt:
                    # Extract EPSG code from WKT
                    import re
                    match = re.search(r'AUTHORITY\["EPSG","(\d+)"\]', crs_wkt)
                    if match:
                        crs_str = f'EPSG:{match.group(1)}'
            
            # Fallback to spatial_ref attribute if available
            if crs_str is None and 'spatial_ref' in spatial_ref.attrs:
                crs_str = spatial_ref.attrs.get('spatial_ref', 'EPSG:4326')
        
        # Final fallback
        if crs_str is None:
            crs_str = 'EPSG:4326'
        
        transform_list = da.attrs.get('transform', None)
        nodata_value = da.attrs.get('nodata', 255)
        description = da.attrs.get('description', 'Flood prediction categories')
        created = da.attrs.get('created', 'Unknown')
        source = da.attrs.get('source', 'Unknown')
        
        # Get coordinate information
        x_coords = da.coords['x'].values if 'x' in da.coords else None
        y_coords = da.coords['y'].values if 'y' in da.coords else None
        
        print(f"CRS: {crs_str}")
        print(f"NoData value: {nodata_value}")
        print(f"Description: {description}")
        print(f"Created: {created}")
        
        # Calculate statistics
        valid_mask = prediction_array != nodata_value
        valid_pixels = np.sum(valid_mask)
        total_pixels = prediction_array.size
        
        print(f"Valid pixels: {valid_pixels:,}/{total_pixels:,} ({valid_pixels/total_pixels*100:.2f}%)")
        
        # Count flood categories
        unique_values, counts = np.unique(prediction_array[valid_mask], return_counts=True)
        print("\nFlood category distribution:")
        for val, count in zip(unique_values, counts):
            if val < len(FloodCategory):
                category_name = FloodCategory(int(val)).name.replace('_', ' ')
                percentage = count / valid_pixels * 100
                print(f"  {category_name}: {count:,} pixels ({percentage:.2f}%)")
        
        return {
            'prediction': prediction_array,
            'nodata_value': nodata_value,
            'valid_mask': valid_mask,
            'crs': crs_str,
            'transform': transform_list,
            'x_coords': x_coords,
            'y_coords': y_coords,
            'metadata': {
                'description': description,
                'created': created,
                'source': source
            },
            'statistics': {
                'unique_values': unique_values,
                'counts': counts,
                'valid_pixels': valid_pixels,
                'total_pixels': total_pixels
            }
        }
        
    except Exception as e:
        print(f"Error loading Zarr prediction: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def create_flood_visualization(pred_data, output_file, title_suffix="", dpi=150, extent=None):
    """
    Create visualization of flood prediction results.
    
    Args:
        pred_data: Dictionary with prediction data and metadata
        output_file: Path to save the visualization
        title_suffix: Additional text for plot title
        dpi: DPI for saved figure
        extent: Tuple of (xmin, ymin, xmax, ymax) for visualization extent
    """
    try:
        print("Creating flood prediction visualization...")
        
        # Extract data
        prediction = pred_data['prediction']
        nodata_value = pred_data['nodata_value']
        valid_mask = pred_data['valid_mask']
        x_coords = pred_data['x_coords']
        y_coords = pred_data['y_coords']
        
        height, width = prediction.shape
        
        # Filter data by extent if provided
        if extent is not None and x_coords is not None and y_coords is not None:
            xmin, ymin, xmax, ymax = extent
            
            # Print coordinate system information for debugging
            print(f"Data coordinate range: X[{x_coords.min():.2f}, {x_coords.max():.2f}], Y[{y_coords.min():.2f}, {y_coords.max():.2f}]")
            print(f"Requested extent: X[{xmin}, {xmax}], Y[{ymin}, {ymax}]")
            
            # Get CRS information
            crs_str = pred_data['crs']
            print(f"Data CRS: {crs_str}")
            
            # Check if extent coordinates are in geographic (lat/lon) vs projected coordinates
            extent_is_geographic = (abs(xmin) <= 180 and abs(xmax) <= 180 and 
                                  abs(ymin) <= 90 and abs(ymax) <= 90)
            data_is_projected = (x_coords.min() > 180 or x_coords.max() > 180 or 
                               abs(y_coords.min()) > 90 or abs(y_coords.max()) > 90)
            
            if extent_is_geographic and data_is_projected:
                try:
                    print("Converting extent from geographic (EPSG:4326) to data CRS...")
                    # Create coordinate transformer
                    transformer = Transformer.from_crs("EPSG:4326", crs_str, always_xy=True)
                    
                    # Transform extent coordinates
                    xmin_proj, ymin_proj = transformer.transform(xmin, ymin)
                    xmax_proj, ymax_proj = transformer.transform(xmax, ymax)
                    
                    print(f"Transformed extent: X[{xmin_proj:.2f}, {xmax_proj:.2f}], Y[{ymin_proj:.2f}, {ymax_proj:.2f}]")
                    
                    # Update extent with transformed coordinates
                    xmin, ymin, xmax, ymax = xmin_proj, ymin_proj, xmax_proj, ymax_proj
                    
                except Exception as e:
                    print(f"Error transforming coordinates: {e}")
                    print("Proceeding without extent filtering.")
                    extent = None
            
            if extent is not None:
                # Find indices within the extent
                x_mask = (x_coords >= xmin) & (x_coords <= xmax)
                y_mask = (y_coords >= ymin) & (y_coords <= ymax)
                
                if np.any(x_mask) and np.any(y_mask):
                    x_indices = np.where(x_mask)[0]
                    y_indices = np.where(y_mask)[0]
                    
                    x_start, x_end = x_indices[0], x_indices[-1] + 1
                    y_start, y_end = y_indices[0], y_indices[-1] + 1
                    
                    # Subset the prediction data
                    prediction = prediction[y_start:y_end, x_start:x_end]
                    valid_mask = valid_mask[y_start:y_end, x_start:x_end]
                    height, width = prediction.shape
                    
                    print(f"Filtered to extent: {height}x{width} pixels")
                else:
                    print(f"Warning: No data found within transformed extent")
                    print("Proceeding with full dataset visualization.")
                    extent = None
        
        # Create colormap for flood categories
        flood_colors = [FLOOD_COLORS[FloodCategory(i)] for i in range(len(FloodCategory))]
        cmap = ListedColormap(flood_colors)
        
        # Check if visualization would be too large
        total_pixels = height * width
        max_viz_pixels = 2000000  # 2 million pixels max
        
        # Downsample if necessary
        if total_pixels > max_viz_pixels:
            downsample_ratio = int(np.ceil(np.sqrt(total_pixels / max_viz_pixels)))
            print(f"Image too large ({height}x{width}). Downsampling by factor of {downsample_ratio}")
            
            prediction_ds = prediction[::downsample_ratio, ::downsample_ratio]
            valid_mask_ds = valid_mask[::downsample_ratio, ::downsample_ratio]
        else:
            prediction_ds = prediction
            valid_mask_ds = valid_mask
        
        # Create masked array for visualization
        prediction_masked = np.ma.masked_where(prediction_ds == nodata_value, prediction_ds)
        
        # Create figure
        plt.figure(figsize=(12, 8), dpi=dpi)
        
        # Main plot
        im = plt.imshow(prediction_masked, cmap=cmap, vmin=0, vmax=4)
        
        # Add title
        main_title = f"Flood Prediction Results{title_suffix}"
        plt.title(main_title, fontsize=16, pad=20)
        
        # Remove axes for cleaner look
        plt.axis('off')
        
        # Add colorbar
        cbar = plt.colorbar(im, shrink=0.6, aspect=20)
        cbar.set_label('Flood Risk Category', fontsize=12)
        
        # Set colorbar ticks and labels
        cbar.set_ticks([0, 1, 2, 3, 4])
        cbar.set_ticklabels([cat.name.replace('_', ' ') for cat in FloodCategory])
        
        # Add statistics text
        stats = pred_data['statistics']
        valid_pixels = stats['valid_pixels']
        total_pixels = stats['total_pixels']
        
        stats_text = f"Valid pixels: {valid_pixels:,} ({valid_pixels/total_pixels*100:.1f}%)"
        plt.figtext(0.02, 0.02, stats_text, fontsize=10, ha='left')
        
        # Add metadata text
        metadata = pred_data['metadata']
        created = metadata.get('created', 'Unknown')
        if created != 'Unknown' and 'T' in created:
            created = created.split('T')[0]  # Show only date part
        
        meta_text = f"Created: {created}"
        plt.figtext(0.98, 0.02, meta_text, fontsize=10, ha='right')
        
        # Adjust layout
        plt.tight_layout()
        
        # Save figure
        plt.savefig(output_file, dpi=dpi, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"Saved visualization to: {output_file}")
        
    except Exception as e:
        print(f"Error creating visualization: {str(e)}")
        import traceback
        traceback.print_exc()

def create_category_histogram(pred_data, output_file, dpi=150):
    """
    Create histogram of flood category distribution.
    
    Args:
        pred_data: Dictionary with prediction data and metadata
        output_file: Path to save the histogram
        dpi: DPI for saved figure
    """
    try:
        print("Creating flood category distribution histogram...")
        
        stats = pred_data['statistics']
        unique_values = stats['unique_values']
        counts = stats['counts']
        valid_pixels = stats['valid_pixels']
        
        # Filter out nodata values and NaN values
        nodata_value = pred_data['nodata_value']
        mask = np.logical_and(unique_values != nodata_value, ~np.isnan(unique_values))
        unique_values = unique_values[mask]
        counts = counts[mask]
        
        # Calculate percentages
        percentages = counts / valid_pixels * 100
        
        # Create figure
        plt.figure(figsize=(10, 6), dpi=dpi)
        
        # Create bar plot
        colors = [FLOOD_COLORS[FloodCategory(int(val))] for val in unique_values]
        bars = plt.bar(unique_values, percentages, color=colors, alpha=0.8, edgecolor='black', linewidth=1)
        
        # Customize plot
        plt.xlabel('Flood Risk Category', fontsize=12)
        plt.ylabel('Percentage of Area (%)', fontsize=12)
        plt.title('Flood Risk Category Distribution', fontsize=14, pad=20)
        
        # Set x-axis labels
        category_names = [FloodCategory(int(val)).name.replace('_', ' ') for val in unique_values]
        plt.xticks(unique_values, category_names, rotation=45, ha='right')
        
        # Add value labels on bars
        for bar, count, pct in zip(bars, counts, percentages):
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                    f'{pct:.1f}%\n({count:,})', 
                    ha='center', va='bottom', fontsize=10)
        
        # Add grid for better readability
        plt.grid(axis='y', alpha=0.3, linestyle='--')
        
        # Adjust layout
        plt.tight_layout()
        
        # Save figure
        plt.savefig(output_file, dpi=dpi, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print(f"Saved histogram to: {output_file}")
        
    except Exception as e:
        print(f"Error creating histogram: {str(e)}")
        import traceback
        traceback.print_exc()

def main(args):
    """Main function to create visualizations from window-by-window results."""
    print(f"Window-by-Window Results Visualization")
    print(f"Input Zarr file: {args.zarr_file}")
    print(f"Output directory: {os.path.dirname(args.output_prefix) or '.'}")
    
    # Load prediction results
    pred_data = load_zarr_prediction(args.zarr_file)
    if pred_data is None:
        print("Failed to load prediction data. Exiting.")
        return
    
    # Create output directory if needed
    output_dir = os.path.dirname(args.output_prefix)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # Create main visualization
    viz_file = f"{args.output_prefix}_visualization.png"
    title_suffix = f" - {args.title_suffix}" if args.title_suffix else ""
    extent = args.extent if hasattr(args, 'extent') and args.extent else None
    create_flood_visualization(pred_data, viz_file, title_suffix, args.dpi, extent)
    
    # Create histogram
    hist_file = f"{args.output_prefix}_histogram.png"
    create_category_histogram(pred_data, hist_file, args.dpi)
    
    print(f"\nVisualization completed successfully!")
    print(f"Files created:")
    print(f"  - Main visualization: {viz_file}")
    print(f"  - Category histogram: {hist_file}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Visualize results from window-by-window DEM inference')
    parser.add_argument('--zarr_file', type=str, required=True,
                        help='Path to the Zarr prediction results file')
    parser.add_argument('--output_prefix', type=str, default='./window_results',
                        help='Output file prefix for visualization files')
    parser.add_argument('--title_suffix', type=str, default='',
                        help='Additional text to add to plot titles')
    parser.add_argument('--dpi', type=int, default=150,
                        help='DPI for saved figures (default: 150)')
    parser.add_argument('--extent', type=float, nargs=4, metavar=('XMIN', 'YMIN', 'XMAX', 'YMAX'),
                        help='Spatial extent to visualize (xmin ymin xmax ymax)')
    
    args = parser.parse_args()
    main(args)