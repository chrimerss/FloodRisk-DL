#!/bin/bash
#==========================================================
# CaMa-Flood sample go script (4) global 15min simulation with "external runoff data"
# Please follow the doc/Guideline.Md about detail, You need to download external runoff data not included in the package to execute this script.
# -- Long-term  simulations (1980 spinup -> 1980 ~ 2014)
# -- Daily runoff forcing (netCDF) at 15min resolution from "E2O WRR2 WCMEF" is used
# -- input matrix is same as the sample ruoff data (test-15min_nc)
#
# (C) X. Zhou, D.Yamazaki & E. Dutra  (U-Tokyo/FCUL)  Feb 2021
#
# Licensed under the Apache License, Version 2.0 (the "License");
#   You may not use this file except in compliance with the License.
#   You may obtain a copy of the License at: http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software distributed under the License is 
#  distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. 
# See the License for the specific language governing permissions and limitations under the License.
#==========================================================

#*** PBS setting when needed
#SBATCH --job-name=US_CITIES_DEM
#SBATCH --time=24:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
#SBATCH --gpus=1
#SBATCH --gpu_cmode=shared
#SBATCH --mem=256G
#SBATCH -p serc

#================================================
# (0) Basic Setting (for workstation)

##
ml python/3.12.1
ml cuda/12.6.1
export HF_HOME=/home/users/li1995/global_flood/FloodRisk-DL/terratorch
cd /home/users/li1995/global_flood/FloodRisk-DL/terratorch/meta_learning
source /home/users/li1995/global_flood/FloodRisk-DL/.venv/bin/activate

# Path to county shapefile
COUNTY_SHAPEFILE="/home/users/li1995/global_flood/FloodRisk-DL/data/download_US_DEM/national_map_downloader/cb_2018_us_county_20m.shp"

# Base directory containing merged DEM Zarr files
ZARR_BASE_DIR="/home/users/li1995/global_flood/FloodRisk-DL/data/download_US_DEM/merged_dem_results"

# Output directory for inference results
OUTPUT_DIR="/home/users/li1995/global_flood/FloodRisk-DL/inference_results"

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR"

# Loop through each Zarr file
for zarr_file in "$ZARR_BASE_DIR"/*_cropped_dem.zarr; do
    if [ -d "$zarr_file" ]; then  # Zarr files are directories
        zarr_filename=$(basename "$zarr_file")
        echo "Processing Zarr file: $zarr_filename"
        
        # Create output filename
        output_filename="$OUTPUT_DIR/inference_${zarr_filename%.zarr}.tif"
        if [ -f "$output_filename" ]; then
            echo "Output file already exists, skipping: $output_filename"
            continue
        fi
        
        # Get location-specific precipitation data using county centroid
        echo "Getting precipitation data for $zarr_filename..."
        rainfall_mm=$(python get_precipitation_zarr.py "$zarr_file" "$COUNTY_SHAPEFILE")
        echo "Using rainfall: ${rainfall_mm}mm for 1-hour, 500-year return period"
        
        # Run the inference for this Zarr file
        python dem_inference_zarr.py \
            --zarr_file="$zarr_file" \
            --rainfall_mm="$rainfall_mm" \
            --batch_size=5000000 \
            --output_file="$output_filename"
        
        # Check if the command was successful
        if [ $? -eq 0 ]; then
            echo "Successfully processed: $zarr_filename"
        else
            echo "Error processing: $zarr_filename"
        fi
    fi
done

echo "All DEM files have been processed."
