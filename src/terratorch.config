# lightning.pytorch==2.1.1
seed_everything: 42
trainer:
  accelerator: auto
  strategy: auto
  devices: auto
  num_nodes: 1
  precision: 16-mixed  # Consider using mixed precision for faster training
  logger:
    class_path: WandbLogger
    init_args:
      project: UrbanFlood2D-Segmentation
      save_dir: outputs/  # Adjust this path as needed
      name: privith
  callbacks:
    - class_path: RichProgressBar
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: epoch
    - class_path: ModelCheckpoint
      init_args:
        dirpath: checkpoints/segmentation
        monitor: val/Multiclass_Jaccard_Index
        mode: max
        filename: best-{epoch:02d}-{val_loss:.4f}
  max_epochs: 500
  log_every_n_steps: 20
  enable_checkpointing: true

data:
  class_path: data.flood_data_seg.FloodDataModule  # Replace with your actual data module
  init_args:
    batch_size: 8  # Adjust based on your GPU memory
    num_workers: 4

model:
  class_path: terratorch.tasks.SemanticSegmentationTask
  init_args:
    model_factory: EncoderDecoderFactory
    model_args:
      backbone: prithvi_eo_v2_300
      backbone_pretrained: true
      backbone_img_size: 512  # Match your input size
      necks:
        - name: ReshapeTokensToImage
        - name: LearnedInterpolateToPyramidal
      decoder: UNetDecoder  # UNetDecoder works well for segmentation
      decoder_channels: [512, 256, 128, 64]
      head_dropout: 0.1
      num_classes: 6  # Set to your number of output classes
    loss: ce  # Cross-entropy loss - alternatives: dice, jaccard, focal
    ignore_index: -1  # Ignore this value in loss calculation
    freeze_backbone: false  # Set to true for transfer learning with limited data

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 1.e-4
    weight_decay: 0.1

lr_scheduler:
  class_path: ReduceLROnPlateau
  init_args:
    monitor: val/loss
    factor: 0.5
    patience: 5